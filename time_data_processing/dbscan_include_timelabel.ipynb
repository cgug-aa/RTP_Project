{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. time label을 추가한 dbscan 비지도 학습\n",
    "\n",
    "#### 1) 보간 하지 않은 어디쉐어 데이터\n",
    "\n",
    "데이터의 위도, 경도, 시간레이블 추출 후 csv 파일로 저장."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#데이터 경로 어디쉐어\n",
    "directory=os.getcwd()+'\\\\data\\\\어디쉐어전처리데이터\\\\___ecfd1086a6934ae08b555b3ae880d31e'\n",
    "\n",
    "# 병합할 빈 DataFrame 생성\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# 폴더 내 모든 CSV 파일에 대해 반복\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        # CSV 파일을 DataFrame으로 읽기\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # 필요한 열만 선택 (lat, lng, output)\n",
    "        df = df[['lat', 'lng', 'TL']]\n",
    "        \n",
    "        # 병합된 DataFrame에 추가\n",
    "        merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "\n",
    "# 결과를 하나의 CSV 파일로 저장\n",
    "merged_df.to_csv('./combined_어디쉐어.csv', index=False)\n",
    "\n",
    "print(\"CSV 파일이 성공적으로 병합되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 포인트를 포함한 전체 csv 파일 dbscan 적용 후 시각화."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CSV 파일 읽기 (파일 경로를 적절히 변경하세요) Dask를 사용해 대용량 CSV 파일을 처리\n",
    "file_path = \"./combined_어디쉐어.csv\"\n",
    "\n",
    "# 데이터프레임 읽기\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "#전체 데이터 경로. 필요한 열만 선택\n",
    "all_lat_lng_TL_lists = [[row['lat'], row['lng'], row['TL']] for _, row in df.iterrows()]\n",
    "\n",
    "# DBSCAN 모델 생성\n",
    "dbscan = DBSCAN(eps=0.001, min_samples=15)\n",
    "labels = dbscan.fit_predict(all_lat_lng_TL_lists)\n",
    "\n",
    "# 결과 시각화\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# 정상 데이터는 파란색, 이상치는 빨간색으로 표시\n",
    "for i in range(0,len(labels),500):\n",
    "        lat=all_lat_lng_TL_lists[i][0]\n",
    "        lng=all_lat_lng_TL_lists[i][1]\n",
    "        TL=all_lat_lng_TL_lists[i][2]\n",
    "        color = 'red' if labels[i] == -1 else 'blue'\n",
    "        ax.scatter(lat, lng, TL, c=color, marker='o')\n",
    "\n",
    "\n",
    "ax.set_xlabel('Latitude')\n",
    "ax.set_ylabel('Longitude')\n",
    "ax.set_zlabel('Time Label')\n",
    "plt.title('DBSCAN Clustering of Geographical Data')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "abnormal_count=0\n",
    "normal_count=0\n",
    "\n",
    "for label in labels:\n",
    "    if label==-1:\n",
    "        abnormal_count+=1\n",
    "    else:\n",
    "        normal_count+=1\n",
    "\n",
    "# 정상 경로/ 이상치 카운트\n",
    "print(f'정상 개수: {normal_count}, 이상치 개수: {abnormal_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 보간 하지 않은 위드라이브 데이터\n",
    "\n",
    "데이터의 위도, 경도, 시간레이블 추출 후 csv 파일로 저장."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "#데이터 경로 위드라이브\n",
    "directory=os.getcwd()+'/data/Label/위드라이브/1be2e43d69994758973f6185bdd973d0'\n",
    "\n",
    "# 병합할 빈 DataFrame 생성\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# 폴더 내 모든 CSV 파일에 대해 반복\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        # CSV 파일을 DataFrame으로 읽기\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # 필요한 열만 선택 (lat, lng, output)\n",
    "        df = df[['lat', 'lng', 'time_label']]\n",
    "        \n",
    "        # 병합된 DataFrame에 추가\n",
    "        merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "\n",
    "# 결과를 하나의 CSV 파일로 저장\n",
    "merged_df.to_csv('./combined_위드라이브.csv', index=False)\n",
    "\n",
    "print(\"CSV 파일이 성공적으로 병합되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 포인트를 포함한 전체 csv 파일 dbscan 적용 후 시각화."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 읽기 (파일 경로를 적절히 변경하세요) Dask를 사용해 대용량 CSV 파일을 처리\n",
    "file_path = \"./combined_위드라이브.csv\"\n",
    "\n",
    "# 데이터프레임 읽기\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "#전체 데이터 경로. 필요한 열만 선택\n",
    "all_lat_lng_TL_lists = [[row['lat'], row['lng'], row['time_label']] for _, row in df.iterrows()]\n",
    "\n",
    "# DBSCAN 모델 생성\n",
    "dbscan = DBSCAN(eps=0.001, min_samples=15)\n",
    "labels = dbscan.fit_predict(all_lat_lng_TL_lists)\n",
    "\n",
    "# 결과 시각화\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# 정상 데이터는 파란색, 이상치는 빨간색으로 표시\n",
    "for i in range(0,len(labels),500):\n",
    "        lat=all_lat_lng_TL_lists[i][0]\n",
    "        lng=all_lat_lng_TL_lists[i][1]\n",
    "        TL=all_lat_lng_TL_lists[i][2]\n",
    "        color = 'red' if labels[i] == -1 else 'blue'\n",
    "        ax.scatter(lat, lng, TL, c=color, marker='o')\n",
    "\n",
    "\n",
    "ax.set_xlabel('Latitude')\n",
    "ax.set_ylabel('Longitude')\n",
    "ax.set_zlabel('Time Label')\n",
    "plt.title('DBSCAN Clustering of Geographical Data')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "abnormal_count=0\n",
    "normal_count=0\n",
    "\n",
    "for label in labels:\n",
    "    if label==-1:\n",
    "        abnormal_count+=1\n",
    "    else:\n",
    "        normal_count+=1\n",
    "\n",
    "# 정상 경로/ 이상치 카운트\n",
    "print(f'정상 개수: {normal_count}, 이상치 개수: {abnormal_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) 보간한 어디쉐어 데이터\n",
    "\n",
    "모든 csv 파일의 경로를 받아 데이터를 보간."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "#데이터 경로(어디쉐어)\n",
    "directory=os.getcwd()+'\\\\data\\\\어디쉐어전처리데이터\\\\___ecfd1086a6934ae08b555b3ae880d31e'\n",
    "\n",
    "#데이터 불러오기 (위도, 경도, 시간레이블)\n",
    "def extract_lat_lng_TL_from_csv(directory):\n",
    "    all_lat_lng_TL_lists = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            df = pd.read_csv(filepath)\n",
    "            lat_lng_list=[[row['lat'], row['lng'], row['TL']] for _, row in df.iterrows()]\n",
    "            all_lat_lng_TL_lists.append(lat_lng_list)   \n",
    "\n",
    "    #결측치 제거\n",
    "    all_lat_lng_TL_lists.pop(-1)\n",
    "\n",
    "    return all_lat_lng_TL_lists\n",
    "\n",
    "#경로 데이터 보간\n",
    "def interpolate_path(path, num_points=10):\n",
    "    latitudes = [point[0] for point in path]\n",
    "    longitudes = [point[1] for point in path]\n",
    "    start_time_labels= [point[2] for point in path]\n",
    "    distances = np.linspace(0, 1, len(path))\n",
    "    interp_lat = interp1d(distances, latitudes, kind='linear')\n",
    "    interp_lon = interp1d(distances, longitudes, kind='linear')\n",
    "    interp_start_TL = interp1d(distances, start_time_labels, kind='linear')\n",
    "    new_distances = np.linspace(0, 1, num_points)\n",
    "    new_latitudes = interp_lat(new_distances)\n",
    "    new_longitudes = interp_lon(new_distances)\n",
    "    new_TL = interp_start_TL(new_distances)\n",
    "    return np.column_stack((new_latitudes, new_longitudes, new_TL)).flatten()\n",
    "\n",
    "# 경로 및 시간(레이블값) 데이터\n",
    "lat_lng_TL_values = extract_lat_lng_TL_from_csv(directory)\n",
    "\n",
    "# 보간된 경로 벡터들\n",
    "path_vectors = np.array([interpolate_path(path) for path in lat_lng_TL_values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보간된 데이터를 통한 dbscan 적용 후 시각화."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DBSCAN 모델링\n",
    "dbscan=DBSCAN(eps=1.2, min_samples=10)\n",
    "labels = dbscan.fit_predict(path_vectors)\n",
    "\n",
    "# 3D 시각화\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for segment, label in zip(path_vectors, labels):\n",
    "    lat=segment[0::3]\n",
    "    lng=segment[1::3]\n",
    "    TL=segment[2::3]\n",
    "    color = 'red' if label == -1 else 'blue'\n",
    "    ax.scatter(lat, lng, TL, c=color, marker='o')\n",
    "\n",
    "ax.set_xlabel('Latitude')\n",
    "ax.set_ylabel('Longitude')\n",
    "ax.set_zlabel('Time Label')\n",
    "plt.title('lat-lng-TL 3D graph')\n",
    "plt.show()\n",
    "\n",
    "normal_count=0\n",
    "abnormal_count=0\n",
    "\n",
    "# 이상치 여부를 'dbscan output' 열에 기록하는 함수\n",
    "def record_outliers(directory, labels, filenames):\n",
    "    for label, filename in zip(labels, filenames):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        global abnormal_count\n",
    "        global normal_count\n",
    "        df = pd.read_csv(filepath)\n",
    "        if 'dbscan output' not in df.columns:\n",
    "            df['dbscan output'] = 1  # 기본값 1로 설정\n",
    "        if label == -1:\n",
    "            df['dbscan output'] = -1  # 이상치일 경우 -1로 설정\n",
    "            abnormal_count+=1\n",
    "        else:\n",
    "            normal_count+=1\n",
    "            \n",
    "        df.to_csv(filepath, index=False)\n",
    "\n",
    "# 이상치 여부를 CSV 파일에 기록\n",
    "record_outliers(directory, labels, os.listdir(directory))\n",
    "\n",
    "# 정상 경로/ 이상치 카운트\n",
    "print(f'정상 개수: {normal_count}, 이상치 개수: {abnormal_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) 보간한 위드라이브 데이터 활용\n",
    "\n",
    "모든 csv 파일의 경로를 받아 데이터를 보간."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 경로(위드라이브)\n",
    "directory=os.getcwd()+'/data/Label/위드라이브/1be2e43d69994758973f6185bdd973d0'\n",
    "\n",
    "#데이터 불러오기 (위도, 경도, 시간레이블)\n",
    "def extract_lat_lng_TL_from_csv(directory):\n",
    "    all_lat_lng_TL_lists = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            df = pd.read_csv(filepath)\n",
    "            lat_lng_list=[[row['lat'], row['lng'], row['time_label']] for _, row in df.iterrows()]\n",
    "            all_lat_lng_TL_lists.append(lat_lng_list)   \n",
    "\n",
    "    #결측치 제거\n",
    "    all_lat_lng_TL_lists.pop(-1)\n",
    "\n",
    "    return all_lat_lng_TL_lists\n",
    "\n",
    "#경로 데이터 보간\n",
    "def interpolate_path(path, num_points=10):\n",
    "    latitudes = [point[0] for point in path]\n",
    "    longitudes = [point[1] for point in path]\n",
    "    start_time_labels= [point[2] for point in path]\n",
    "    distances = np.linspace(0, 1, len(path))\n",
    "    interp_lat = interp1d(distances, latitudes, kind='linear')\n",
    "    interp_lon = interp1d(distances, longitudes, kind='linear')\n",
    "    interp_start_TL = interp1d(distances, start_time_labels, kind='linear')\n",
    "    new_distances = np.linspace(0, 1, num_points)\n",
    "    new_latitudes = interp_lat(new_distances)\n",
    "    new_longitudes = interp_lon(new_distances)\n",
    "    new_TL = interp_start_TL(new_distances)\n",
    "    return np.column_stack((new_latitudes, new_longitudes, new_TL)).flatten()\n",
    "\n",
    "# 경로 및 시간(레이블값) 데이터\n",
    "lat_lng_TL_values = extract_lat_lng_TL_from_csv(directory)\n",
    "\n",
    "# 보간된 경로 벡터들\n",
    "path_vectors = np.array([interpolate_path(path) for path in lat_lng_TL_values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보간된 데이터를 통한 dbscan 적용 후 시각화."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DBSCAN 모델링\n",
    "dbscan=DBSCAN(eps=1.2, min_samples=10)\n",
    "labels = dbscan.fit_predict(path_vectors)\n",
    "\n",
    "# 3D 시각화\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for segment, label in zip(path_vectors, labels):\n",
    "    lat=segment[0::3]\n",
    "    lng=segment[1::3]\n",
    "    TL=segment[2::3]\n",
    "    color = 'red' if label == -1 else 'blue'\n",
    "    ax.scatter(lat, lng, TL, c=color, marker='o')\n",
    "\n",
    "ax.set_xlabel('Latitude')\n",
    "ax.set_ylabel('Longitude')\n",
    "ax.set_zlabel('Time Label')\n",
    "plt.title('lat-lng-TL 3D graph')\n",
    "plt.show()\n",
    "\n",
    "normal_count=0\n",
    "abnormal_count=0\n",
    "\n",
    "# 이상치 여부를 'dbscan output' 열에 기록하는 함수\n",
    "def record_outliers(directory, labels, filenames):\n",
    "    for label, filename in zip(labels, filenames):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        global abnormal_count\n",
    "        global normal_count\n",
    "        df = pd.read_csv(filepath)\n",
    "        if 'dbscan output' not in df.columns:\n",
    "            df['dbscan output'] = 1  # 기본값 1로 설정\n",
    "        if label == -1:\n",
    "            df['dbscan output'] = -1  # 이상치일 경우 -1로 설정\n",
    "            abnormal_count+=1\n",
    "        else:\n",
    "            normal_count+=1\n",
    "            \n",
    "        df.to_csv(filepath, index=False)\n",
    "\n",
    "# 이상치 여부를 CSV 파일에 기록\n",
    "record_outliers(directory, labels, os.listdir(directory))\n",
    "\n",
    "# 정상 경로/ 이상치 카운트\n",
    "print(f'정상 개수: {normal_count}, 이상치 개수: {abnormal_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. start_time과 end_time을 추가한 dbscan 비지도 학습\n",
    "\n",
    "#### 1) 보간한 위드라이브 데이터\n",
    "\n",
    "경로 데이터 보간."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 경로\n",
    "directory=os.getcwd()+'/data/Label/위드라이브/1be2e43d69994758973f6185bdd973d0'\n",
    "\n",
    "#파일에 따른 start, end TimeLabel 리스트\n",
    "start_end_list=[]\n",
    "\n",
    "#데이터 불러오기 (위도, 경도, 시간레이블)\n",
    "def extract_lat_lng_TL_from_csv(directory):\n",
    "    all_lat_lng_TL_lists = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            df = pd.read_csv(filepath)\n",
    "            lat_lng_list=[]\n",
    "            for index, row in df.iterrows():\n",
    "                lat_lng_list.append([row['lat'], row['lng']])\n",
    "                if index==0:\n",
    "                    s=row['time_label']\n",
    "                elif index==(df.shape[0]-1):\n",
    "                    e=row['time_label']\n",
    "            start_end_list.append([s, e])\n",
    "            all_lat_lng_TL_lists.append(lat_lng_list)   \n",
    "\n",
    "    #결측치 제거\n",
    "    all_lat_lng_TL_lists.pop(-1)\n",
    "    start_end_list.pop(-1)\n",
    "\n",
    "    return all_lat_lng_TL_lists\n",
    "\n",
    "#경로 데이터 보간\n",
    "def interpolate_path(path, num_points=10):\n",
    "    latitudes = [point[0] for point in path]\n",
    "    longitudes = [point[1] for point in path]\n",
    "    start_time_labels= [point[2] for point in path]\n",
    "    end_time_labels= [point[3] for point in path]\n",
    "    distances = np.linspace(0, 1, len(path))\n",
    "    interp_lat = interp1d(distances, latitudes, kind='linear')\n",
    "    interp_lon = interp1d(distances, longitudes, kind='linear')\n",
    "    interp_start_TL = interp1d(distances, start_time_labels, kind='linear')\n",
    "    interp_end_TL = interp1d(distances, end_time_labels, kind='linear')\n",
    "    new_distances = np.linspace(0, 1, num_points)\n",
    "    new_latitudes = interp_lat(new_distances)\n",
    "    new_longitudes = interp_lon(new_distances)\n",
    "    new_start_TL = interp_start_TL(new_distances)\n",
    "    new_end_TL=interp_end_TL(new_distances)\n",
    "    return np.column_stack((new_latitudes, new_longitudes, new_start_TL, new_end_TL)).flatten()\n",
    "\n",
    "# 경로 및 시간(레이블값) 데이터\n",
    "lat_lng_TL_values = extract_lat_lng_TL_from_csv(directory)\n",
    "\n",
    "# 경로에 start, end 레이블 추가하기\n",
    "for location, time in zip(lat_lng_TL_values, start_end_list):\n",
    "    for point in location:\n",
    "        point.extend(time)\n",
    "\n",
    "# 보간된 경로 벡터들\n",
    "path_vectors = np.array([interpolate_path(path) for path in lat_lng_TL_values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dbscan 모델링, 시각화."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DBSCAN 모델링\n",
    "dbscan=DBSCAN(eps=1.2, min_samples=15)\n",
    "labels = dbscan.fit_predict(path_vectors)\n",
    "\n",
    "\n",
    "normal_count=0\n",
    "abnormal_count=0\n",
    "\n",
    "# 이상치 여부를 'dbscan output' 열에 기록하는 함수\n",
    "def record_outliers(directory, labels, filenames):\n",
    "    for label, filename in zip(labels, filenames):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        global abnormal_count\n",
    "        global normal_count\n",
    "        df = pd.read_csv(filepath)\n",
    "        if 'dbscan output' not in df.columns:\n",
    "            df['dbscan output'] = 1  # 기본값 1로 설정\n",
    "        if label == -1:\n",
    "            df['dbscan output'] = -1  # 이상치일 경우 -1로 설정\n",
    "            abnormal_count+=1\n",
    "        else:\n",
    "            normal_count+=1\n",
    "            \n",
    "        df.to_csv(filepath, index=False)\n",
    "\n",
    "# 이상치 여부를 CSV 파일에 기록\n",
    "record_outliers(directory, labels, os.listdir(directory))\n",
    "\n",
    "# 정상 경로/ 이상치 카운트\n",
    "print(f'정상 개수: {normal_count}, 이상치 개수: {abnormal_count}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
